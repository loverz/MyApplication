# Spark介绍

大数据计算框架，官方定义为：通用的大数据快速处理引擎

包含大数据常见的计算框架

* Spark Core 离线计算
* Spark sql 交互式查询
* Spark Streaming 实时流计算
* Spark MLlib 机器学习
* Spark GraphX 用于图计算

一般 Spark用于大数据计算 hadoop用于大数据存储，资源调度（Yarn）

##### Spark计算处理速度快的原因

- 基于内存的计算方式
- 基于DAG 有向无环图（在[图论](https://baike.baidu.com/item/%E5%9B%BE%E8%AE%BA)中，如果一个[有向图](https://baike.baidu.com/item/%E6%9C%89%E5%90%91%E5%9B%BE)无法从某个顶点出发经过若干条边回到该点，则这个图是一个**有向无环图**）



##### Spark运行架构图

![img](https:////blog-10039692.file.myqcloud.com/1493710441713_3905_1493710442164.png)

![img](https:////blog-10039692.file.myqcloud.com/1493710470901_4658_1493710471619.png)

##### Spark模型 master-slave 模型

Master对应的集群中含有Master进程的节点，Slave对应的集群中含有Worker进程的节点

* Master 整个集群控制器，负责整个集群正常运行
* Worker作为计算节点，负责接收主节点命令进行状态汇报
* Executor 负责任务执行
* Client 用户客户端，提交应用
* Driver 负责应用执行

##### 基本概念

* application  Spark应用程序，包含一个Driver Program和若干Executor
* SparkContext ：Spark应用程序入口，负责调度各个运算资源，协调各个Worker Node上的executor
* Driver program ：运行Application的main，创建SparkContext
* Executor：是Application运行在Worker node上的一个进程，负责运行task，每个application都会申请自己的executor来执行任务
* Cluster Manager:用于集群中获取资源的外部服务
* Worker node:集群中任何一个可以运行Application的节点，运行一个或者多个executor进程
* Task：运行在executor的工作单元
* Job：SparkContext 提交的具体Action操作，常与Action对应
* Stage：每个job被拆分成很多组task，也称为TaskSet
* RDD:弹性分布式数据集，核心模块和类
* DAGScheduler => 根据Job构建基于Stage的DAG，并提交Stage给TaskScheduler
* TaskScheduler => 将Taskset提交给Worker node集群运行并返回结果
* Transformations => 是Spark API的一种类型，Transformation返回值还是一个RDD，所有的Transformation采用的都是懒策略，如果只是将Transformation提交是不会执行计算的
* Action => 是Spark API的一种类型，Action返回值不是一个RDD，而是一个scala集合；计算只有在Action被提交的时候计算才被触发。

##### RDD

![img](https:////blog-10039692.file.myqcloud.com/1493710739191_5851_1493710739472.png)